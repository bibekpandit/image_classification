{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing import image\n",
    "from keras.applications import resnet50\n",
    "%matplotlib inline\n",
    "import os, math\n",
    "import numpy as np\n",
    "import keras\n",
    "from keras import backend as K\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Activation\n",
    "#following added by JMS \n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from keras.layers.core import Dense, Flatten\n",
    "from keras.optimizers import SGD, Adam\n",
    "from keras.metrics import categorical_crossentropy\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.models import Model\n",
    "from keras.models import load_model\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import itertools\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.models import load_model\n",
    "import h5py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def label_names(label_vector, classes):\n",
    "    \"\"\"\n",
    "    Get label names from y vector.\n",
    "    \n",
    "    Args:\n",
    "        label_vector : vector of ones and zeros representing y_value of a data instance\n",
    "        classes : a list of all the possible classes whose order aligns with y_value\n",
    "    \"\"\"\n",
    "    assert label_vector.size == len(classes)\n",
    "    l = []\n",
    "    for i,x in enumerate(label_vector):\n",
    "        if x==1:\n",
    "            l.append(classes[i])\n",
    "    return l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Below taken from fastai\n",
    "def plots(ims, figsize=(12,6), rows=1, interp=False, titles=None, classes=None):\n",
    "    if type(ims[0]) is np.ndarray:\n",
    "        ims = np.array(ims).astype(np.uint8)\n",
    "        if (ims.shape[-1] != 3):\n",
    "            ims = ims.transpose((0,2,3,1))\n",
    "    f = plt.figure(figsize=figsize)\n",
    "    cols = len(ims)//rows if len(ims) % 2 == 0 else len(ims)//rows + 1\n",
    "    for i in range(len(ims)):\n",
    "        sp = f.add_subplot(rows, cols, i+1)\n",
    "        sp.axis('Off')\n",
    "        if titles is not None:\n",
    "            sp.set_title(label_names(titles[i], classes), fontsize=8)\n",
    "        plt.imshow(ims[i], interpolation=None if interp else 'none')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code taken from stackoverflow post\n",
    "def zca_whitening_matrix(X):\n",
    "    \"\"\"\n",
    "    Function to compute ZCA whitening matrix (aka Mahalanobis whitening).\n",
    "    INPUT:  X: [M x N] matrix.\n",
    "        Rows: Variables\n",
    "        Columns: Observations\n",
    "    OUTPUT: ZCAMatrix: [M x M] matrix\n",
    "    \"\"\"\n",
    "    # Covariance matrix [column-wise variables]: Sigma = (X-mu)' * (X-mu) / N\n",
    "    sigma = np.cov(X, rowvar=True) # [M x M]\n",
    "    # Singular Value Decomposition. X = U * np.diag(S) * V\n",
    "    U,S,V = np.linalg.svd(sigma)\n",
    "        # U: [M x M] eigenvectors of sigma.\n",
    "        # S: [M x 1] eigenvalues of sigma.\n",
    "        # V: [M x M] transpose of U\n",
    "    # Whitening constant: prevents division by zero\n",
    "    epsilon = 1e-5\n",
    "    # ZCA Whitening matrix: U * Lambda * U'\n",
    "    ZCAMatrix = np.dot(U, np.dot(np.diag(1.0/np.sqrt(S + epsilon)), U.T)) # [M x M]\n",
    "    return ZCAMatrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def whiten_batch(X):\n",
    "    X_norm = np.multiply(X, 1.0/255.0, casting=\"unsafe\")\n",
    "    flatx = np.reshape(X_norm, (-1, np.prod(X_norm.shape[-3:])))\n",
    "    ZCAMatrix = zca_whitening_matrix(flatx)\n",
    "    ZCAMatrix.shape\n",
    "    xZCAMatrix = np.dot(ZCAMatrix, flatx) # project X onto the ZCAMatrix\n",
    "    X_hat = np.reshape(xZCAMatrix, X.shape)\n",
    "    return X_hat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Loading Data</h2>\n",
    "<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_path = \"data/train.h5\"\n",
    "valid_path = \"data/validate.h5\"\n",
    "train_augment_path = \"data/train_augment.h5\"\n",
    "valid_augment_path = \"data/validate_augment.h5\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with h5py.File(train_path, 'r') as hf:\n",
    "    X_train, y_train = hf['images'][:], hf['labels'][:]\n",
    "\n",
    "with h5py.File(valid_path, 'r') as hf:\n",
    "    X_valid, y_valid = hf['images'][:], hf['labels'][:]\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "use_augment = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset also contains augmented data\n",
    "if use_augment:\n",
    "    with h5py.File(train_augment_path, 'r') as hf:\n",
    "        X_train_aug, y_train_aug = hf['images'][:], hf['labels'][:]\n",
    "\n",
    "    with h5py.File(valid_augment_path, 'r') as hf:\n",
    "        X_valid_aug, y_valid_aug = hf['images'][:], hf['labels'][:]\n",
    "    \n",
    "    \n",
    "    X_train = np.concatenate((X_train, X_train_aug), axis=0)\n",
    "    y_train = np.concatenate((y_train, y_train_aug), axis=0)\n",
    "    X_valid = np.concatenate((X_valid, X_valid_aug), axis=0)\n",
    "    y_valid = np.concatenate((y_valid, y_valid_aug), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(y_train.shape, y_train_aug.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datagen = ImageDataGenerator(featurewise_center=True,\n",
    "                             featurewise_std_normalization=True,\n",
    "                             rotation_range=20,\n",
    "                             width_shift_range=0.2,\n",
    "                             height_shift_range=0.2,\n",
    "                             horizontal_flip=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datagen.fit(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = ['cat', 'dog', 'rabbit']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Creating/Loading Pre-Trained ResNet Model</h2>\n",
    "<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Keras' ResNet50 model that was pre-trained against the ImageNet database\n",
    "model = resnet50.ResNet50()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#take off last layer\n",
    "model.layers.pop()\n",
    "\n",
    "#freeze layers\n",
    "for layer in model.layers[:-2]:\n",
    "    layer.trainable=False\n",
    "\n",
    "#make last layer    \n",
    "last = model.layers[-1].output\n",
    "x = Dense(len(classes), activation=\"softmax\")(last)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#set training steps based on the # of images\n",
    "num_train_samples = X_train.shape[0]\n",
    "num_valid_samples = X_valid.shape[0]\n",
    "# num_valid_samples = sum([len(files) for r, d, files in os.walk(validate_path)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_train_steps = math.floor(num_train_samples/BATCH_SIZE)\n",
    "num_valid_steps = math.floor(num_valid_samples/BATCH_SIZE)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Compile and Train model</h2>\n",
    "<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def testModel(X, y, model):\n",
    "    predictions = model.predict(X, True)\n",
    "    # for each image get the index of the class with max probability\n",
    "    int_predictions = np.argmax(predictions, axis=1)\n",
    "    int_labels = np.argmax(y, axis=1)\n",
    "    \n",
    "    count = 0\n",
    "    for i in range(int_labels.size):\n",
    "        if int_predictions[i] == int_labels[i]:\n",
    "            count += 1\n",
    "    return count/int_labels.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 80\n",
    "learning_rate = 0.0001\n",
    "decay_rate = learning_rate / epochs\n",
    "momentum = 0.8\n",
    "adam = Adam(lr=learning_rate, beta_1=0.8, beta_2=0.999, decay=decay_rate, epsilon=0.0000001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#finetune model \n",
    "finetuned_model = Model(model.input, x)\n",
    "finetuned_model.compile(optimizer=adam, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "best_loss = float(\"inf\")\n",
    "\n",
    "for e in range(epochs):\n",
    "    print('Epoch', e)\n",
    "    batches = 0\n",
    "    for X_batch, y_batch in datagen.flow(X_train, y_train, batch_size=BATCH_SIZE):\n",
    "        X_batch_whitened = whiten_batch(X_batch)\n",
    "        finetuned_model.fit(X_batch_whitened, y_batch)\n",
    "        batches += 1\n",
    "#         print(\"batch:\", batches)\n",
    "        if batches >= len(X_train) / 32:\n",
    "            # we need to break the loop by hand because\n",
    "            # the generator loops indefinitely\n",
    "            break\n",
    "    \n",
    "    score = finetuned_model.evaluate(X_valid, y_valid, verbose=0)\n",
    "    if score[0] < best_loss:\n",
    "        print(\"Validation loss improved from\", best_loss, \"to\", score[0])\n",
    "        best_loss = score[0]\n",
    "        finetuned_model.save('models/resnet50.h5')\n",
    "        \n",
    "    print('Valid loss:', score[0], 'Valid accuracy:', score[1])\n",
    "\n",
    "finetuned_model.save('models/resnet50.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_probs = finetuned_model.predict(images, True)\n",
    "# for each image get the index of the class with max probability\n",
    "predictions = np.argmax(pred_probs, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Confusion Matrix</h2>\n",
    "<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "true_labels = np.argmax(labels, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = confusion_matrix(true_labels, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# From Scikit Learn\n",
    "\n",
    "def plot_confusion_matrix(cm, classes,\n",
    "                          normalize=False,\n",
    "                          title='Confusion matrix',\n",
    "                          cmap=plt.cm.Blues):\n",
    "    \"\"\"\n",
    "    This function prints and plots the confusion matrix.\n",
    "    Normalization can be applied by setting `normalize=True`.\n",
    "    \"\"\"\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        print(\"Normalized confusion matrix\")\n",
    "    else:\n",
    "        print('Confusion matrix, without normalization')\n",
    "        \n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=45)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "\n",
    "    fmt = '.2f' if normalize else 'd'\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, format(cm[i, j], fmt),\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "    fig = plt.gcf()\n",
    "    fig.set_size_inches(16, 16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "cm_plot_labels = classes\n",
    "plot_confusion_matrix(cm, cm_plot_labels, title = 'Confusion Matrix')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Stacked Histogram</h2>\n",
    "<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy_by_label(true_labels, predicted_labels, label_names):\n",
    "    correct, incorrect = [0]*len(label_names), [0]*len(label_names)\n",
    "    for true, predict in zip(true_labels, predicted_labels):\n",
    "        if true == predict:\n",
    "            correct[true] += 1\n",
    "        else:\n",
    "            incorrect[true] += 1\n",
    "    return correct, incorrect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = len(classes)\n",
    "correct, incorrect = accuracy_by_label(true_labels, predictions, classes)\n",
    "ind = np.arange(N)    # the x locations for the groups\n",
    "width = 0.35       # the width of the bars: can also be len(x) sequence\n",
    "\n",
    "p1 = plt.bar(ind, correct, width)\n",
    "p2 = plt.bar(ind, incorrect, width,\n",
    "             bottom=correct)\n",
    "\n",
    "plt.ylabel('Number of Images')\n",
    "plt.title('Correct Classification vs Incorrect Classification')\n",
    "plt.xticks(ind, classes)\n",
    "plt.yticks(np.arange(0, 100, 20))\n",
    "plt.legend((p1[0], p2[0]), ('Correct', 'Incorrect'))\n",
    "fig = plt.gcf()\n",
    "fig.set_size_inches(28, 18)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
