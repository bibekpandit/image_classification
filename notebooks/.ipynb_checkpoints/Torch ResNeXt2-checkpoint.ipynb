{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch, os\n",
    "from torch.utils import data\n",
    "from torch.autograd import Variable\n",
    "import torch.nn as nn\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import resNeXt_pytorch\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Defining the ResNext Class</h2>\n",
    "<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Bottleneck(nn.Module):\n",
    "    cardinality = 32  # the size of the set of transformations\n",
    "\n",
    "    def __init__(self, nb_channels_in, nb_channels, nb_channels_out, stride=1):\n",
    "        super().__init__()\n",
    "\n",
    "        self.conv1 = nn.Conv2d(nb_channels_in, nb_channels, kernel_size=1)\n",
    "        self.bn1 = nn.BatchNorm2d(nb_channels)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "\n",
    "        self.conv2 = nn.Conv2d(nb_channels, nb_channels, kernel_size=3, stride=stride, padding=1, groups=self.cardinality)\n",
    "        self.bn2 = nn.BatchNorm2d(nb_channels)\n",
    "\n",
    "        self.conv3 = nn.Conv2d(nb_channels, nb_channels_out, kernel_size=1)\n",
    "        self.bn3 = nn.BatchNorm2d(nb_channels_out)\n",
    "\n",
    "        if nb_channels_in != nb_channels_out or stride != 1:\n",
    "            self.project = nn.Conv2d(nb_channels_in, nb_channels_out, kernel_size=1, stride=stride)\n",
    "        else:\n",
    "            self.project = None\n",
    "\n",
    "    def forward(self, x):\n",
    "        residual = x\n",
    "\n",
    "        out = self.conv1(x)\n",
    "        out = self.bn1(out)\n",
    "        out = self.relu(out)\n",
    "\n",
    "        out = self.conv2(out)\n",
    "        out = self.bn2(out)\n",
    "        out = self.relu(out)\n",
    "\n",
    "        out = self.conv3(out)\n",
    "        out = self.bn3(out)\n",
    "\n",
    "        if callable(self.project):\n",
    "            residual = self.project(residual)\n",
    "\n",
    "        out += residual\n",
    "        out = self.relu(out)\n",
    "\n",
    "        return out\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Using Bottleneck to implement ResNeXt</h2>\n",
    "<p>ResNeXt are very deep convolutional neural networks. For performance and tunability, we use smaller building block CNNs to implement a very deep ResNeXt.</p>\n",
    "<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResNeXt(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        # conv1\n",
    "        self.conv1 = nn.Conv2d(3, 64, kernel_size=7, stride=2, padding=3)\n",
    "        self.bn1 = nn.BatchNorm2d(64)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "\n",
    "        # conv2\n",
    "        self.max_pool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
    "\n",
    "        conv2 = []\n",
    "        for i in range(2):\n",
    "            nb_channels_in = 64 if i == 0 else 256\n",
    "            conv2.append(Bottleneck(nb_channels_in, 128, 256))\n",
    "\n",
    "        self.conv2 = nn.Sequential(*conv2)\n",
    "\n",
    "        # conv3\n",
    "        conv3 = []\n",
    "        for i in range(2):\n",
    "            if i == 0:\n",
    "                nb_channels_in = 256\n",
    "                stride = 2\n",
    "            else:\n",
    "                nb_channels_in = 512\n",
    "                stride = 1\n",
    "\n",
    "            conv3.append(Bottleneck(nb_channels_in, 256, 512, stride=stride))\n",
    "\n",
    "        self.conv3 = nn.Sequential(*conv3)\n",
    "\n",
    "        # conv4\n",
    "        conv4 = []\n",
    "        for i in range(2):\n",
    "            if i == 0:\n",
    "                nb_channels_in = 512\n",
    "                stride = 2\n",
    "            else:\n",
    "                nb_channels_in = 1024\n",
    "                stride = 1\n",
    "\n",
    "            conv4.append(Bottleneck(nb_channels_in, 512, 1024, stride=stride))\n",
    "\n",
    "        self.conv4 = nn.Sequential(*conv4)\n",
    "\n",
    "        # conv5\n",
    "        conv5 = []\n",
    "        for i in range(2):\n",
    "            if i == 0:\n",
    "                nb_channels_in = 1024\n",
    "                stride = 2\n",
    "            else:\n",
    "                nb_channels_in = 2048\n",
    "                stride = 1\n",
    "\n",
    "            conv5.append(Bottleneck(nb_channels_in, 1024, 2048, stride=stride))\n",
    "\n",
    "        self.conv5 = nn.Sequential(*conv5)\n",
    "\n",
    "        self.avg_pool = nn.AvgPool2d(7)\n",
    "        self.fc = nn.Linear(2048, 2)\n",
    "        self.soft = nn.Softmax()\n",
    "\n",
    "    def forward(self, x):\n",
    "        # conv1\n",
    "        x = self.conv1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.relu(x)\n",
    "\n",
    "        # conv2\n",
    "        x = self.max_pool(x)\n",
    "        for block in self.conv2:\n",
    "            x = block(x)\n",
    "\n",
    "        # conv3\n",
    "        for block in self.conv3:\n",
    "            x = block(x)\n",
    "\n",
    "        # conv4\n",
    "        for block in self.conv4:\n",
    "            x = block(x)\n",
    "\n",
    "        # conv5\n",
    "        for block in self.conv5:\n",
    "            x = block(x)\n",
    "\n",
    "        x = self.avg_pool(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.fc(x)\n",
    "\n",
    "        return self.soft(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Dataset class to maintain and load data</h2>\n",
    "<p>Dataset Class simplifies the data loading process by taking care of the back of the scene work that goes into getting the images and converting them into appropriate torch tensors as well as preparing the labels.</p>\n",
    "<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dataset(data.Dataset):\n",
    "    'Characterizes a dataset for PyTorch'\n",
    "    def __init__(self, samples, all_labels, transform):\n",
    "        'Initialization'\n",
    "        self.all_labels = all_labels\n",
    "        self.samples = samples\n",
    "        self.transform = transform\n",
    "        self.output_dimension = len(all_labels)\n",
    "\n",
    "    def __len__(self):\n",
    "        'Denotes the total number of samples'\n",
    "        return len(self.samples)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        'Generates one sample of data'\n",
    "        # Select sample\n",
    "        instance_path, instance_label = self.samples[index]\n",
    "\n",
    "        # Load data and get label\n",
    "        instance_data = Dataset.loadImage(instance_path)\n",
    "        X = self.transform(instance_data)\n",
    "        y = self.vectorLabel(self.all_labels.index(instance_label))\n",
    "        if torch.cuda.is_available():\n",
    "            X = X.cuda()\n",
    "            y = y.cuda()\n",
    "        return X, y\n",
    "\n",
    "    def vectorLabel(self, label):\n",
    "        one_hot_vector = np.zeros(self.output_dimension, dtype = 'float32')\n",
    "        one_hot_vector[label] = 1\n",
    "        return torch.from_numpy(one_hot_vector)\n",
    "    \n",
    "    @staticmethod\n",
    "    def loadImage(infilename):\n",
    "        img = Image.open(infilename)\n",
    "        img.load()\n",
    "        return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getData(data_dir, labels):\n",
    "    samples_and_labels = []\n",
    "    for [path, dirname, files] in os.walk(data_dir):\n",
    "        label = re.search('[^/]+$', path).group(0)\n",
    "        if label not in labels:\n",
    "            continue\n",
    "        for file in files:\n",
    "            samples_and_labels.append((\"{0}/{1}\".format(path,file), label))\n",
    "    return samples_and_labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Training</h3>\n",
    "<p>Training requires setting up the model, retrieving data, training and validation</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ResNeXt()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {'batch_size': 64,\n",
    "          'shuffle': True,\n",
    "          'num_workers': 6}\n",
    "max_epochs = 4\n",
    "all_labels = ['cat', 'dog']\n",
    "\n",
    "# use transforms.ToTensor\n",
    "\n",
    "transform = transforms.Compose([transforms.Resize(224),\n",
    "                                transforms.CenterCrop(224),\n",
    "                                transforms.ToTensor(),\n",
    "                                transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
    "\n",
    "# Datasets\n",
    "train_samples = getData(\"images/train\", all_labels)\n",
    "valid_samples = getData(\"images/valid\", all_labels)\n",
    "# Generators\n",
    "training_set, validation_set = Dataset(train_samples, all_labels, transform), Dataset(valid_samples, all_labels, transform)\n",
    "training_generator = data.DataLoader(training_set, **params)\n",
    "validation_generator = data.DataLoader(validation_set, **params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = torch.nn.BCELoss(size_average=True)\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(max_epochs):\n",
    "    for local_batch, local_labels in training_generator:\n",
    "        input = Variable(local_batch)\n",
    "        target = Variable(local_labels)\n",
    "        prediction = model.forward(Variable(input))\n",
    "        loss = criterion(prediction, target)\n",
    "        print(epoch, loss.data[0])\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(target)\n",
    "print(prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
