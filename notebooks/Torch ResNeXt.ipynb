{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.models as models\n",
    "import torchvision.datasets as datasets\n",
    "import torchvision.transforms as transforms\n",
    "import resNeXt_pytorch\n",
    "from torch.autograd.variable import Variable\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "import resNeXt_pytorch\n",
    "import net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate=None\n",
    "toOneHot = True\n",
    "dimension = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def learning_rate_schedule(optimizer, epoch):\n",
    "    global learning_rate\n",
    "    lr = learning_rate * (0.1 ** int(epoch / 30))\n",
    "    for param_group in optimizer.param_groups:\n",
    "        param_group['lr'] = lr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(train_loader, model, lossfn, optimizer, epoch):\n",
    "    model.train()\n",
    "    for i, (input, target) in enumerate(train_loader):\n",
    "        if toOneHot:\n",
    "            target = toOneHot(dimension, target)\n",
    "        target = target.cuda(non_blocking=True)\n",
    "#         target = target.cpu()\n",
    "        output = model(input)\n",
    "        \n",
    "        loss = lossfn(output, target)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    print(\"Training Loss\", loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate(val_loader, model, lossfn):\n",
    "    \n",
    "    model.eval()\n",
    "    accuracies = []\n",
    "    with torch.no_grad():\n",
    "        for i, (input, target) in enumerate(val_loader):\n",
    "            if toOneHot:\n",
    "                target = toOneHot(dimension, target)\n",
    "            target = target.cuda(non_blocking=True)\n",
    "#             target = target.cpu()\n",
    "\n",
    "            output = model(input)\n",
    "            loss = lossfn(output, target)\n",
    "\n",
    "            acc1 = accuracy(output, target)\n",
    "            accuracies.extend(acc1)\n",
    "#             if i % 10 == 0:\n",
    "#                 print( 'Top 1 accuracy: {:.2}, Top 5 accuracy: {:.2}'.format(acc1[0], acc5[0]))\n",
    "\n",
    "    return np.mean(accuracies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(output, target, topk=(1,)):\n",
    "    with torch.no_grad():\n",
    "        maxk = max(topk)\n",
    "        batch_size = target.size(0)\n",
    "\n",
    "        _, pred = output.topk(maxk, 1, True, True)\n",
    "        \n",
    "        pred = pred.t()\n",
    "        correct = pred.eq(target.view(1, -1).expand_as(pred))\n",
    "\n",
    "        res = []\n",
    "        for k in topk:\n",
    "            correct_k = correct[:k].view(-1).float().sum(0, keepdim=True)\n",
    "            res.append(correct_k.mul_(100.0 / batch_size))\n",
    "        return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_checkpoint(state, best, filename='checkpoint.tar'):\n",
    "    torch.save(state, filename)\n",
    "    if best:\n",
    "        shutil.copyfile(filename, 'best_checkpoint.tar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def toOneHot(dimension, int_target):\n",
    "    int_target = int_target.numpy()\n",
    "    n = int_target.size\n",
    "    one_hot_vector = np.zeros((n, dimension), dtype = 'float32')\n",
    "    one_hot_vector[np.arange(n), int_target] = 1\n",
    "    return torch.from_numpy(one_hot_vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pretrained = False\n",
    "distributed = False\n",
    "\n",
    "# architecture = 'resnet18'\n",
    "# print('creating model {}'.format(architecture))\n",
    "\n",
    "model = resNeXt_pytorch.ResNeXt()\n",
    "print(model)\n",
    "# model = models.__dict__[architecture](pretrained=pretrained)\n",
    "\n",
    "model = torch.nn.DataParallel(model).cuda()  #change this to .cuda() if gpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lossfn = nn.MSELoss().cuda()  #change this to .cuda() if gpu\n",
    "global learning_rate\n",
    "learning_rate = 0.008\n",
    "momentum = 0.9\n",
    "weight_decay = 1e-4\n",
    "optimizer = torch.optim.Adam(model.parameters(),\n",
    "                            learning_rate,\n",
    "                            weight_decay=weight_decay)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 40"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datadir = 'images'\n",
    "traindir, valdir = os.path.join(datadir, 'train'), os.path.join(datadir, 'valid')\n",
    "print('constructing training/validation datasets')\n",
    "\n",
    "\n",
    "train_batch, valid_batch = 10, 4\n",
    "train_workers, valid_workers = 1, 1\n",
    "normalize = transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.2, 0.2, 0.2])  # This should be computed on our images\n",
    "transform = transforms.Compose([transforms.RandomResizedCrop(224),\n",
    "                                transforms.RandomHorizontalFlip(),\n",
    "                                transforms.ToTensor(),\n",
    "                                normalize,])\n",
    "\n",
    "train_dataset, valid_dataset = datasets.ImageFolder(traindir, transform), datasets.ImageFolder(valdir, transform)\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=train_batch, shuffle=True,\n",
    "                                           num_workers=train_workers, pin_memory=False)\n",
    "val_loader = torch.utils.data.DataLoader(valid_dataset, batch_size=valid_batch, shuffle = True,\n",
    "                                         num_workers=valid_workers, pin_memory=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_precision = 0\n",
    "print( 'training over {} epochs'.format(epochs) )\n",
    "for epoch in range(epochs):\n",
    "    print(\"Epoch\", epoch)\n",
    "    learning_rate_schedule(optimizer, epoch)\n",
    "\n",
    "    train(train_loader, model, lossfn, optimizer, epoch)\n",
    "    precision = validate(val_loader, model, lossfn)\n",
    "    print(\"Validation Accuracy\", precision)\n",
    "    is_best = precision > best_precision\n",
    "    best_precision = max(precision, best_precision)\n",
    "    save_checkpoint({\n",
    "        'epoch': epoch+1,\n",
    "        'arch': architecture,\n",
    "        'state_dict': model.state_dict(),\n",
    "        'best_precision': best_precision,\n",
    "        'optimizer' : optimizer.state_dict(),\n",
    "    }, is_best)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Testing</h2>\n",
    "<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datadir = 'images'\n",
    "testdir = os.path.join(datadir, 'test')\n",
    "\n",
    "test_workers = 1\n",
    "\n",
    "test_dataset = datasets.ImageFolder(testdir, transform)\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=len(test_dataset), shuffle = True,\n",
    "                                          num_workers=test_workers, pin_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "for data_batch, labels_batch in test_loader:\n",
    "\n",
    "#     move to GPU if available\n",
    "    \n",
    "    data_batch, labels_batch = data_batch.cuda(async=True), labels_batch.cuda(async=True)\n",
    "    print(type(labels_batch))\n",
    "    target = labels_batch\n",
    "#     fetch the next evaluation batch\n",
    "#     data_batch, labels_batch = Variable(data_batch), Variable(labels_batch)\n",
    "\n",
    "#     compute model output\n",
    "    output_batch = model(data_batch)\n",
    "#     loss = loss_fn(output_batch, labels_batch)\n",
    "    _, pred = output_batch.topk(1, 1)\n",
    "    pred = pred.t()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = target.cpu()\n",
    "target = target.numpy()\n",
    "prediciton = pred.reshape(-1).cpu()\n",
    "prediction = prediciton.numpy()\n",
    "if toOneHot:\n",
    "    prediction = [np.where(r==1)[0][0] for r in prediction]\n",
    "# assert (target.size() == prediction.size())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Confusion Matrix</h2>\n",
    "<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "%matplotlib inline\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import itertools\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = confusion_matrix(target, prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_confusion_matrix(cm, classes,\n",
    "                          normalize=False,\n",
    "                          title='Confusion matrix',\n",
    "                          cmap=plt.cm.Blues):\n",
    "    \"\"\"\n",
    "    This function prints and plots the confusion matrix.\n",
    "    Normalization can be applied by setting `normalize=True`.\n",
    "    \"\"\"\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        print(\"Normalized confusion matrix\")\n",
    "    else:\n",
    "        print('Confusion matrix, without normalization')\n",
    "\n",
    "    print(cm)\n",
    "\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=45)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "\n",
    "    fmt = '.2f' if normalize else 'd'\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, format(cm[i, j], fmt),\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm_plot_labels = ['cat', 'dog']\n",
    "plot_confusion_matrix(cm, cm_plot_labels, title = 'Confusion Matrix')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
