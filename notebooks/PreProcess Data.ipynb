{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import os\n",
    "import numpy as np\n",
    "import itertools\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "from tqdm import tqdm\n",
    "import h5py\n",
    "import json\n",
    "from collections import defaultdict\n",
    "from PIL import Image\n",
    "from keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Methods</h2>\n",
    "<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def readJsonData(json_file):\n",
    "    \"\"\"\n",
    "    Reads json_file's data and returns it as a Python dictionary\n",
    "    Args:\n",
    "        json_file: path of the json file to be read along with .json extension\n",
    "    \"\"\"\n",
    "    with open(json_file) as data:\n",
    "        return json.load(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# path to dictionary which maps image ID's to image label classes. Multiple labels is allowed\n",
    "dict_of_labels = readJsonData(\"data/image_labels.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getLabel(file_path):\n",
    "    ID = os.path.splitext(file_path)[0].split('/')[-1]\n",
    "    if ID in dict_of_labels:\n",
    "        return dict_of_labels[ID]\n",
    "    # The augmented images have id which is the original id followed by '_' followed by other numbers\n",
    "    if '_' in ID:\n",
    "        ID = ID[:ID.rfind('_')]\n",
    "        return dict_of_labels[ID]\n",
    "    raise AssertionError(\"ID not in root dictionary\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "common_img_extensions = {'.tif', '.tiff', '.gif', '.jpeg', '.jpg', '.jif', '.jfif',\n",
    "                         '.jp2', '.jpx', '.j2k', '.j2c', '.fpx', '.pcd', '.png'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "STANDARD_SIZE=(224,224)\n",
    "\n",
    "def load_image(filename, verbose=False):\n",
    "    \"\"\"\n",
    "    takes a filename and turns it into a numpy array of RGB pixels\n",
    "    \"\"\"\n",
    "    img = Image.open(filename)\n",
    "    if verbose==True:\n",
    "        print( \"(%s) changing size from %s to %s\" % (filename, str(img.size), str(STANDARD_SIZE)) )\n",
    "    img = img.resize(STANDARD_SIZE)\n",
    "    res = np.array(img.getdata(), dtype=np.int16)\n",
    "    if img.mode != 'RGB':\n",
    "        if img.mode == 'RGBA':\n",
    "            res = res[:,0:3]\n",
    "        else:\n",
    "            imgc = Image.new('RGB', img.size)\n",
    "            imgc.paste(img)\n",
    "            res = np.array(imgc.getdata(), dtype=np.int16)\n",
    "\n",
    "    return res.reshape(STANDARD_SIZE+(3,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load(rootdir, include):\n",
    "    \"\"\"\n",
    "    Load images from rootdir as numpy arrays.\n",
    "    \n",
    "    Args:\n",
    "        rootdir : path to the directory containing images\n",
    "        include : the classes you want to include while loading data\n",
    "    \"\"\"\n",
    "    print('loading facets and filenames from {}'.format(rootdir))\n",
    "    imgs = defaultdict(set)\n",
    "    \n",
    "    for root,_,files in os.walk(rootdir):\n",
    "        for f in files:\n",
    "            extension = os.path.splitext(f)[1]\n",
    "            if not extension in common_img_extensions:\n",
    "                continue\n",
    "            facet = os.path.split(root)[-1]\n",
    "            if facet in include:\n",
    "                ffull = os.path.join(root,f)\n",
    "                imgs[facet].add(ffull)\n",
    "    X_res = []\n",
    "    y_res = []\n",
    "    for facet, files in imgs.items():\n",
    "        print( 'processing {}: {} files'.format(facet, len(files)) )\n",
    "        for f in tqdm(files):\n",
    "            data = load_image(f)\n",
    "            label = [facet]\n",
    "#             if you want multi label settings stored in dictionary loaded above, comment the above line and uncomment\n",
    "#             the following two lines\n",
    "#             label = getLabel(f)\n",
    "#             label = [x for x in label if x in include]\n",
    "            X_res.append(data)\n",
    "            y_res.append(label)\n",
    "\n",
    "    return np.array(X_res),np.array(y_res)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Load Images</h2>\n",
    "<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = ['cat', 'dog', 'rabbit']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_path = \"data/train\"\n",
    "validate_path = \"data/validate\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train = load(train_path, classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_valid, y_valid = load(validate_path, classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x = X_train\n",
    "train_y = MultiLabelBinarizer(classes).fit_transform(y_train)\n",
    "\n",
    "valid_x = X_valid\n",
    "valid_y = MultiLabelBinarizer(classes).fit_transform(y_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(type(train_x))\n",
    "print(type(train_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(train_x.shape)\n",
    "print(train_y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_h5_name = 'data/train.h5'\n",
    "valid_h5_name = 'data/validate.h5'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with h5py.File(train_h5_name, 'w') as hf:\n",
    "    hf.create_dataset(\"images\",  data=train_x)\n",
    "    hf.create_dataset(\"labels\", data = train_y)\n",
    "\n",
    "with h5py.File(valid_h5_name, 'w') as hf:\n",
    "    hf.create_dataset(\"images\",  data=valid_x)\n",
    "    hf.create_dataset(\"labels\", data = valid_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with h5py.File(train_h5_name, 'r') as hf:\n",
    "        X = hf['images'][:]\n",
    "        y = hf['labels'][:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X.shape)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datagen = ImageDataGenerator(horizontal_flip=True)\n",
    "X_batch, y_batch = next(datagen.flow(X, y, batch_size=4))\n",
    "print(X_batch.shape)\n",
    "print(y_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# code taken from fastai\n",
    "\n",
    "def plots(ims, figsize=(12,6), rows=1, interp=False, titles=None):\n",
    "    if type(ims[0]) is np.ndarray:\n",
    "        ims = np.array(ims).astype(np.uint8)\n",
    "        if (ims.shape[-1] != 3):\n",
    "            ims = ims.transpose((0,2,3,1))\n",
    "    f = plt.figure(figsize=figsize)\n",
    "    cols = len(ims)//rows if len(ims) % 2 == 0 else len(ims)//rows + 1\n",
    "    for i in range(len(ims)):\n",
    "        sp = f.add_subplot(rows, cols, i+1)\n",
    "        sp.axis('Off')\n",
    "        if titles is not None:\n",
    "            sp.set_title(titles[i], fontsize=8)\n",
    "        plt.imshow(ims[i], interpolation=None if interp else 'none')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images, labels = X_batch, y_batch\n",
    "plots(images, titles = labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
